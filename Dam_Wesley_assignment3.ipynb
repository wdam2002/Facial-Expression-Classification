{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":64655,"databundleVersionId":7079324,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-29T20:51:35.722308Z","iopub.execute_input":"2023-11-29T20:51:35.722822Z","iopub.status.idle":"2023-11-29T20:51:35.729640Z","shell.execute_reply.started":"2023-11-29T20:51:35.722782Z","shell.execute_reply":"2023-11-29T20:51:35.727474Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Load data\ntrain_data = pd.read_csv(\"/kaggle/input/cs4210-fall2023-assignment3/train_data.csv\", header=None)\ntrain_target = pd.read_csv(\"/kaggle/input/cs4210-fall2023-assignment3/train_target.csv\", header=None)\ntest_data = pd.read_csv(\"/kaggle/input/cs4210-fall2023-assignment3/test_data.csv\", header=None)\n\n# Split the training data into train and validation sets\ntrain_data, val_data, train_target, val_target = train_test_split(train_data, train_target, test_size=0.2, random_state=42)\n\n# Convert data to PyTorch tensors\ntrain_data = torch.Tensor(train_data.values).view(-1, 1, 48, 48)\ntrain_target = torch.Tensor(train_target.values).squeeze().long()\n\nval_data = torch.Tensor(val_data.values).view(-1, 1, 48, 48)\nval_target = torch.Tensor(val_target.values).squeeze().long()\n\nmean = torch.mean(train_data / 255.0)\nstd = torch.std(train_data / 255.0)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:51:35.731976Z","iopub.execute_input":"2023-11-29T20:51:35.732373Z","iopub.status.idle":"2023-11-29T20:51:40.393966Z","shell.execute_reply.started":"2023-11-29T20:51:35.732344Z","shell.execute_reply":"2023-11-29T20:51:40.391871Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create a custom dataset class\nclass FacialExpressionDataset(Dataset):\n    def __init__(self, data, target, transform=None):\n        self.data = data\n        self.target = target\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image, target = self.data[idx], self.target[idx]\n        sample = {'image': image, 'target': target}\n\n        if self.transform:\n            sample['image'] = self.transform(image)\n\n        return sample","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:51:40.395429Z","iopub.execute_input":"2023-11-29T20:51:40.395777Z","iopub.status.idle":"2023-11-29T20:51:40.406053Z","shell.execute_reply.started":"2023-11-29T20:51:40.395750Z","shell.execute_reply":"2023-11-29T20:51:40.402120Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(),\n    transforms.Normalize(mean=[mean], std=[std])\n])\n\n# Create datasets and dataloaders\ntrain_dataset = FacialExpressionDataset(train_data, train_target, transform=transform)\nval_dataset = FacialExpressionDataset(val_data, val_target, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:51:40.407678Z","iopub.execute_input":"2023-11-29T20:51:40.408018Z","iopub.status.idle":"2023-11-29T20:51:40.424578Z","shell.execute_reply.started":"2023-11-29T20:51:40.407989Z","shell.execute_reply":"2023-11-29T20:51:40.423483Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Build a CNN Model via Subclassing nn.Module\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool = nn.MaxPool2d(kernel_size=2, padding=0)\n        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n        self.fc2 = nn.Linear(256, 3)  # Output has 3 classes: 0-Angry, 1-Happy, and 2-Neutral\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(-1, 128 * 6 * 6)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Instantiate the model, loss function, and optimizer\nmodel = CNNModel()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Learning Rate Scheduler\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:51:40.426598Z","iopub.execute_input":"2023-11-29T20:51:40.426901Z","iopub.status.idle":"2023-11-29T20:51:40.449869Z","shell.execute_reply.started":"2023-11-29T20:51:40.426880Z","shell.execute_reply":"2023-11-29T20:51:40.448882Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Train the model\nnum_epochs = 20\n\nfor epoch in range(num_epochs):\n    model.train()\n    for batch in train_loader:\n        inputs, labels = batch['image'], batch['target']\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # Validate the model\n    model.eval()\n    with torch.no_grad():\n        total_correct = 0\n        total_samples = 0\n        for batch in val_loader:\n            inputs, labels = batch['image'], batch['target']\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total_correct += (predicted == labels).sum().item()\n            total_samples += labels.size(0)\n\n        accuracy = total_correct / total_samples\n        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.4f}')\n        \n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:51:40.450924Z","iopub.execute_input":"2023-11-29T20:51:40.452252Z","iopub.status.idle":"2023-11-29T21:03:08.492258Z","shell.execute_reply.started":"2023-11-29T20:51:40.452195Z","shell.execute_reply":"2023-11-29T21:03:08.491048Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/20, Loss: 0.7018, Validation Accuracy: 0.6337\nEpoch 2/20, Loss: 0.5522, Validation Accuracy: 0.6866\nEpoch 3/20, Loss: 0.5491, Validation Accuracy: 0.7323\nEpoch 4/20, Loss: 1.1940, Validation Accuracy: 0.5917\nEpoch 5/20, Loss: 0.4309, Validation Accuracy: 0.7447\nEpoch 6/20, Loss: 0.4841, Validation Accuracy: 0.7688\nEpoch 7/20, Loss: 0.3099, Validation Accuracy: 0.7719\nEpoch 8/20, Loss: 0.6518, Validation Accuracy: 0.7703\nEpoch 9/20, Loss: 0.2193, Validation Accuracy: 0.7774\nEpoch 10/20, Loss: 0.4318, Validation Accuracy: 0.7719\nEpoch 11/20, Loss: 0.2808, Validation Accuracy: 0.7793\nEpoch 12/20, Loss: 0.3579, Validation Accuracy: 0.7799\nEpoch 13/20, Loss: 0.2271, Validation Accuracy: 0.7842\nEpoch 14/20, Loss: 0.3124, Validation Accuracy: 0.7777\nEpoch 15/20, Loss: 0.2203, Validation Accuracy: 0.7750\nEpoch 16/20, Loss: 0.2296, Validation Accuracy: 0.7802\nEpoch 17/20, Loss: 0.5476, Validation Accuracy: 0.7737\nEpoch 18/20, Loss: 0.2710, Validation Accuracy: 0.7833\nEpoch 19/20, Loss: 0.6337, Validation Accuracy: 0.7781\nEpoch 20/20, Loss: 0.2850, Validation Accuracy: 0.7765\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert test data to PyTorch tensor\nX_test_tensor = torch.Tensor(test_data.values).view(-1, 1, 48, 48)\n\n# Create test dataset and dataloader\ntest_dataset = FacialExpressionDataset(X_test_tensor, torch.zeros(len(X_test_tensor)), transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n# Make predictions\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = batch['image']\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.numpy())\n\n# Save predictions in the required format\nsubmission_df = pd.DataFrame({'Id': range(len(predictions)), 'Category': predictions})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T21:03:08.493690Z","iopub.execute_input":"2023-11-29T21:03:08.494033Z","iopub.status.idle":"2023-11-29T21:03:12.694629Z","shell.execute_reply.started":"2023-11-29T21:03:08.494003Z","shell.execute_reply":"2023-11-29T21:03:12.693257Z"},"trusted":true},"execution_count":14,"outputs":[]}]}